---
title: "Stock Market Movement Classification"
output: github_document
bibliography: "biblio.bib"
lang: "en"
csl: "apa.csl"
---

The main objective of this analysis is to create a Generalized Linear Model based on a logistic regression model in order to classify, based on a series of predictors, which direction is the market going on a given day.

The data used for this analysis as well as the methodology can be found in @introstatlearn. It contains a series of variables related to the S&P 500, a few rows of the data is shown below. The lag columns represent previous values for returns on the index and the `Direction` column represents whether the market went up or down on that particular day, based on the `Today` variable.

```{r setup, echo=FALSE, message=FALSE}
library(ISLR2)
library(tidyverse)
library(MASS)
data("Smarket")
attach(Smarket)
```

```{r}
head(Smarket)
```

Performing a simple descriptive analysis is straightforward with `R`. From the output one can see that the variable `Direction` has only two possible values and that they're qualitative. During the fitting step of the process the functions will create dummy variables to address this non-quantitative predictor.

```{r}
# Print basic statistics
summary(Smarket)
# Also get correlation matrix for all columns except last one
cor(Smarket[,-9])
```

The correlation matrix showed that no relevant correlations are present in the data set, aside from a `Volume ~ Year` which came out at around $0.539$. A plot of this correlation is shown below. This is in a way intuitive, as one would expect that the stock market trade volume increases over the years as companies issue more stock. 

```{r, echo=FALSE, fig.cap="Jitter has been added to the plot for ease of analysis."}
Smarket %>% 
  ggplot(aes(Year, Volume)) +
  geom_point(position="jitter") +
  theme_minimal()
```

## Logistic Regression Analysis

For starters, we fit a simple logistic regression model on the data with the full data set in order to get a full model with all relevant variables included, this will help understand which variables might be useful for future models.

In this first model we will not be using a testing set, the importance of this approach lies on the fact that as mentioned before, we're using this first model to test which variables could be relevant, further testing will assess both model training and model testing.

```{r}
# First attempt at a logistic regression model
# Fit a model with lag variables and the volume
glm.fit <- glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, 
               data = Smarket, 
               family = "binomial") # Prediction can only take on two values
# Inspect the p-values for the model
summary(glm.fit)
```

From the summary we can see that no predictors show a relavant statistical significance, thus we can drop the highest *p-valued* predictors from future models.

In order to get the overall training accuracy we create a vector with length $n$, where $n$ represents the total amount of observations on the data set and we change the values according to the results obtained with the model.

```{r}
# Measure the overall training accuracy
glm.probs <- predict(glm.fit, type = 'response') # 'response' to get the actual calculated values

glm.pred <- rep('Down', length(Smarket[,1])) # Create vector of size [1250,] with all values 'Down'
glm.pred[glm.probs > .5] <- 'Up' # Substitute all values where 'Up' was predicted
rm(glm.probs)
```

Lastly, we compare the results vector with the original data to get the accuracy.^[To find out which value is assigned for the ranges $[0, 0.5)$ and $(0.5, 1]$ the contrasts() function was employed on the 'Direction' predictor]

```{r}
# Get training accuracy
mean(glm.pred == Direction)
```

The overall accuracy for this model is around 52.16%, just marginally better than guessing, not exactly a great result. Especially when considering that this accuracy has been using the training set, which is what one would expect the model is trying to minimize the error for.

### Assessing training accuracy
The following approach tries to get a better understanding of the expected performance for the previous model. To achieve this, the data set will be divided into a test set containing 80% of the data observations and a test set containing the remaining 20%. A model will be fitted using the training subset and the accuracy will be tested against the test subset.

Aditionally, as stated previously, some predictors showed no particular statistical significance when it comes to predicting the direction of the market, so we'll drop most of them and keep the two most *significant* for our analysis, which in our case are `Lag1` and `Lag2`.

```{r, echo=FALSE}
# Create training and test vectors to use for bootstrap
l <- length(Smarket[,1])
training = 1:(l - l/5)
testing = (l - l/5 + 1):l
```

```{r}
# Spliting the data set into training and testing
# Training on 4/5 of the data
training.set <- Smarket[training,]
# Test on 1/5 of the data
testing.set <- Smarket[testing,]

# Train a new model with training set
glm.fit <- glm(
  Direction ~ Lag1 + Lag2,
  data = training.set,
  family = "binomial"
)
```

```{r, echo=FALSE}
# Measure the overall training accuracy
glm.probs <- predict(glm.fit, testing.set, type = 'response') # 'response' to get the actual calculated values

glm.pred <- rep('Down', length(testing))
glm.pred[glm.probs > .5] <- 'Up' # Substitute all values where 'Up' was predicted
rm(glm.probs)
```


```{r}
# Get test accuracy
glm.acc <- mean(glm.pred == Direction[1:length(testing)])
glm.acc
```

As seen in the previous output, the model accuracy using a testing set is around 51.2%, which now is marginally worse than the previous model. Clearly logistic regression is not a suitable classification model for this data. 

## Linear Discriminant Analysis
The next approach in this analysis is using an *LDA* model in search of improving the performance obtained by the logistic regression approach shown previously.

The same train-test approach will be followed from now on and most of the code will be skipped to keep things simple, though it'll be available in the Github repository for review.

### Training the model

We'll hereby train a Linear Discriminant Analysis using MASS library's `lda` function, which is essentially the same as the standard linear model `lm` function. Note that the same two-variable subset will be used for fitting instead of the whole variable set. 

```{r}
lda.fit <- lda(
  Direction ~ Lag1 + Lag2,
  training.set
)
```

### Testing the model
After fitting the model we can make predictions for the test set and get a confusion matrix in order to analyze sensitivity and specificity.

```{r}
# Test the accuracy of a linear approach
lda.pred <- predict(lda.fit, testing.set)
table(lda.pred$class, testing.set$Direction)
```

The next code snippet provides the test accuracy for this particular approach, which can also be calculated using the confusion matrix shown above. Note how using linear discriminant analysis compared to logistic regression the overall accuracy increased by more than 6%.

```{r}
lda.acc <- mean(lda.pred$class == testing.set$Direction)
lda.acc
```

## Quadratic Discriminant Analysis
The final approach which will be discussed in this report is the quadratic discriminant analysis, which is esentially a polynomial regression model for classification.

This model uses practically the same syntax as the previous example, except that in this case the function used is MASS' `qda`. The fitting and testing of this model is as straighforward as the previous model.

```{r}
qda.fit <- qda(
  Direction ~ Lag1 + Lag2,
  training.set
)
```

```{r}
qda.pred <- predict(qda.fit, testing.set)
qda.acc <- mean(qda.pred$class == testing.set$Direction)
qda.acc
```

This is actually a pretty good model for the data, close to 60% of accuracy is an outstanding fit for predicting stock market fluctuations; however, the table shown below provides more insight on the model's performance. As can be seen from the table, although the model did improve in overall accuracy, caution must be given to the fact that this model has a sensitivity of about 74.47% while having a specificty of around 35.78%, which means that in this particular data set the model is over-optimistic.

```{r}
table(qda.pred$class, testing.set$Direction)
```

## Final results

Finally the results for our tests can be seen in the following plot, for this particular stock market data set it seems that the most useful model is the Quadratic Discriminant Analysis model; however due to the nature of stock market fluctuation this may not be true for other data sets. Also, even though the overall accuracy improved progressively as we moved across the models, sensitivity and specificity prove that not only overall accuracy need to be taken into consideration when deciding whether an actual model is or not useful.

```{r, echo=FALSE}
tibble("Model"=c("LogRegression", "LDA", "QDA"), "Accuracy"=c(glm.acc, lda.acc, qda.acc)) %>%
  mutate(Model = reorder(Model, Accuracy)) %>% 
  ggplot(aes(Model, Accuracy)) +
  geom_segment(aes(Model, xend=Model, y=0, yend=Accuracy), color="black") +
  geom_point( color="orange", size=4) +
  theme_minimal() +
  ylim(0,.7)
```


# Bibliography
